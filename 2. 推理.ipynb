{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在预训练模型上推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import DetInferencer\n",
    "import os\n",
    "\n",
    "# 初始化模型\n",
    "inferencer = DetInferencer(model='rtmdet_tiny_8xb32-300e_coco')\n",
    "\n",
    "# 推理示例图片\n",
    "dir_path = 'demo/output/'\n",
    "for root, _, files in os.walk(dir_path):\n",
    "    for file in files:\n",
    "        file_path = root + file\n",
    "        inferencer(file_path, show=False, out_dir='outputs')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 列出所有可用预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import DetInferencer\n",
    "\n",
    "models = DetInferencer.list_models('mmdet')\n",
    "f = open(\"checkpoints/models.txt\", mode='a')\n",
    "for model in models:\n",
    "    f.write(model + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用训练好的drinks detection进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e71532fb26447d390a0f99b61401af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_dir/best_coco_bbox_mAP_epoch_40.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ftc/env/miniconda3/envs/gpu-pytorch/lib/python3.9/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'cola': 0.691167950630188}, {'pepsi': 0.41596314311027527}]\n",
      "[{'pepsi': 0.7269371151924133}]\n",
      "[{'ice': 0.8287444114685059}, {'king': 0.48595941066741943}, {'ice': 0.4603344202041626}]\n",
      "[{'sprint': 0.8920233249664307}]\n",
      "[{'cola': 0.6313148736953735}, {'pepsi': 0.534765899181366}, {'milk': 0.5287198424339294}, {'cola': 0.4615095853805542}, {'cola': 0.4609217345714569}, {'milk': 0.44551658630371094}, {'milk': 0.4289666712284088}, {'pepsi': 0.40107619762420654}]\n",
      "[{'pepsi': 0.9433363080024719}]\n",
      "[{'pepsi': 0.7445791959762573}]\n",
      "[{'cola': 0.5446531772613525}]\n",
      "[{'ice': 0.7680181264877319}, {'scream': 0.5150898098945618}]\n",
      "[{'cola': 0.5495877265930176}, {'king': 0.5239288210868835}]\n",
      "[{'cola': 0.7904008030891418}, {'cola': 0.5363962650299072}, {'cola': 0.4448905885219574}, {'cola': 0.44208449125289917}, {'pepsi': 0.4226892590522766}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import DetInferencer\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# pretrained_model: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_tiny_8xb32-300e_coco/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\n",
    "LABEL_MAP = {\n",
    "    0: \"cola\",\n",
    "    1: \"pepsi\",\n",
    "    2: \"sprite\",\n",
    "    3: \"fanta\",\n",
    "    4: \"sprint\",\n",
    "    5: \"ice\",\n",
    "    6: \"scream\",\n",
    "    7: \"milk\",\n",
    "    8: \"red\",\n",
    "    9: \"king\"\n",
    "}\n",
    "\n",
    "\n",
    "def load_json(config_file):\n",
    "    with open(config_file, mode='r', encoding='utf-8') as f:\n",
    "        json_dict = json.load(f)     \n",
    "        return json_dict\n",
    "\n",
    "\n",
    "def get_top_res(json_dict) -> list:\n",
    "    res_list = []\n",
    "    SCORE_THRESHOLD = 0.4\n",
    "    \n",
    "    labels = json_dict[\"labels\"]\n",
    "    scores = json_dict[\"scores\"]\n",
    "    for i in range(len(scores)):\n",
    "        score = scores[i]\n",
    "        if score > SCORE_THRESHOLD:\n",
    "            res_list.append({LABEL_MAP[int(labels[i])]: score})\n",
    "        else:\n",
    "            break\n",
    "    return res_list\n",
    "\n",
    "def get_cfg(output_dir):\n",
    "    for root, _, files in os.walk(output_dir):\n",
    "        if len(files) > 0:\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                json_dict = load_json(file_path)\n",
    "                yield json_dict\n",
    "\n",
    "# 初始化模型\n",
    "inferencer = DetInferencer(model='configs/rtmdet/rtmdet_tiny_1xb12-40e_drinks.py', \n",
    "                           weights='work_dir/best_coco_bbox_mAP_epoch_40.pth',\n",
    "                           device='cuda:0')\n",
    "\n",
    "\n",
    "dir_path = 'data/Drink_284_Detection_coco/test'\n",
    "out_dir = 'outputs'\n",
    "json_dir = os.path.join(out_dir, \"preds\")\n",
    "inferencer(dir_path, out_dir=out_dir, no_save_pred=False, print_result=False)\n",
    "\n",
    "\n",
    "\n",
    "res_list = []\n",
    "\n",
    "for cfg in get_cfg(json_dir):\n",
    "    res = get_top_res(cfg)\n",
    "    print(res)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
